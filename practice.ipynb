{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from collections import namedtuple, deque\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0005\n",
    "gamma         = 0.98\n",
    "buffer_limit  = 50000\n",
    "batch_size    = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'reward', 'next_state'))\n",
    "\n",
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition: ([0], 1, 2, [3])\n",
      "transition: ([1], 2, 3, [4])\n",
      "transition: ([2], 3, 4, [5])\n",
      "transition: ([3], 4, 5, [6])\n",
      "transition: ([4], 5, 6, [7])\n",
      "state shape: 1\n",
      "action: 2\n",
      "reward: 3\n",
      "next state shape: 4\n",
      "\n",
      "state shape: 3\n",
      "action: 4\n",
      "reward: 5\n",
      "next state shape: 6\n",
      "\n",
      "state shape: 0\n",
      "action: 1\n",
      "reward: 2\n",
      "next state shape: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test ReplayBuffer class\n",
    "memory = ReplayMemory(5)\n",
    "\n",
    "# Add 5 transitions to the buffer\n",
    "for i in range(5):\n",
    "    transition = ([i], i+1, i+2, [i+3])\n",
    "    print(f\"transition: {transition}\")\n",
    "    memory.push(*transition)\n",
    "\n",
    "len(memory)\n",
    "\n",
    "# Sample 3 transitions from the buffer\n",
    "transitions = memory.sample(3)\n",
    "\n",
    "# Check if the shape of the tensors is correct\n",
    "for transition in transitions:\n",
    "    print(f\"state shape: {transition.state[0]}\")\n",
    "    print(f\"action: {transition.action}\")\n",
    "    print(f\"reward: {transition.reward}\")\n",
    "    print(f\"next state shape: {transition.next_state[0]}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRQN(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions, n_time_steps):\n",
    "        super(DRQN, self).__init__()\n",
    "        self.n_observations = n_observations\n",
    "        self.n_actions = n_actions\n",
    "        self.n_time_steps = n_time_steps\n",
    "        self.hidden_size = 128\n",
    "        self.rnn = nn.LSTM(self.n_observations, self.hidden_size, num_layers=2)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.n_actions)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(2, 1, 128),\n",
    "                torch.zeros(2, 1, 128))\n",
    "    def forward(self, x):\n",
    "        x = x.view(1, 1, self.n_observations)\n",
    "        x, self.hidden = self.rnn(x, self.hidden)\n",
    "        x = self.fc(x.view(1, -1))\n",
    "        return x.view(1, self.n_actions)\n",
    "    \n",
    "        # self.layer1 = nn.Linear(n_observations, round(n_observations/2))\n",
    "        # self.layer2 = nn.Linear(round(n_observations/2), round(n_observations/2))\n",
    "        # self.layer3 = nn.Linear(round(n_observations/2), n_actions)\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    # def forward(self, x):\n",
    "    #     x = F.relu(self.layer1(x))\n",
    "    #     x = F.relu(self.layer2(x))\n",
    "    #     return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drqn = DRQN(4, 2)\n",
    "x_data = torch.tensor([[[1, 2, 3, 4],\n",
    "                  [2, 3, 4, 5],\n",
    "                  [3, 4, 5, 5],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [6, 7, 8, 9]]], dtype=torch.float32)\n",
    "x_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
